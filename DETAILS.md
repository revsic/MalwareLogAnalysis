# tf-branch-malware

Malware log analysis based on Branch data.

Branch data refers to the metadata from the branching operation such as jmp and call. This data is advantageous for showing the structure of binary regardless of the machine code polymorphism.

[preprocess.py](./utils/preprocess.py) preprocess the raw branch logs to regularized data. Then [classifier](./classifier/model.py) classify the branch data into malware and normal software.

- [utils](#utils) : Utilities for log analysis.
- [cuckoo](#cuckoo) : Helper method for [Cuckoo sandbox](https://github.com/cuckoosandbox/cuckoo) binding.
- [data](#data) : Preprocessed log data for training classifier.
- [BranchTracer](https://github.com/revsic/BranchTracer) : Branch tracer based on VEH for logging branch data.
- [classifier](#classifier) : Classify API sequence between malware and benign.

## Utils

Utilities for log analysis.

- [malwaredb.py](./utils/malwaredb.py) : Create database for the branch logs.
- [preprocess.py](./utils/preprocess.py) : Log preprocessor to train classifier.

### Malware Database

Table **malware**

| column | type | content |
| -- | -- | -- |
| id | Integer | identifier, primary key |
| name | String | name of the malware |

Table **branch**

| column | type | content |
| -- | -- | -- |
| id | Integer | identifier, primary key |
| order | Integer | order of branch data |
| src_addr | Integer | source address |
| dst_addr | Integer | destination address |
| dll | String | name of the dll |
| symbol | String | symbol of the destination address |
| malware_id | Integer | foreign key of **malware.id** |

### Preprocessing

Convert brach data to index set based on ./log/function_list.txt.

For example, let's think about one preprocessed data [1,186,0,143,187,0,292]. First column is label, whether malware(=1) or not(=0). Following columns represent the symbol of API call. Those are one-based index from ./log/function_list.txt. If it is zero, it is unknown symbol according to the function list.

## Cuckoo

Helper method for Cuckoo sandbox binding to automate malware analysis.

<img src="rsrc/cuckoo_structure.png" width="60%">

It is a schematic representation of the structure of the Cuckoo Sandbox. When we submit a malware to the Cuckoo sandbox, scheduler recieve the malware. It sent the malware to the vm or put it into the queue. The `agent.py` of the VM receive it and start the `analyzer.py` to analyze malware. It makes the report and send it to the scheduler.

[analyzer_patch.py](./cuckoo/analyzer_patch.py) is the example to run branch tracer with cuckoo sandbox. Helper injects the Brancher to the target process and Brancher logs the branch data.
```Python
if is32bit:
    self.target = 'C:\\dbg\\Helper32.exe'
else:
    self.target = 'C:\\dbg\\Helper64.exe'

try:
    proc = Popen(self.target)
    pids = proc.pid
except Exception as e:
    log.error('custom : fail to open process %s : %s', self.target, e)
```
After run the software, patched analyzer would send the branch data to main frame of Cuckoo sandbox.
```Python
time.sleep(3)
with open('C:\\dbg\\log.txt') as f_log:
    raw = f_log.read()
    data = ''.join(raw.split('\x00'))
    log.debug('logged : \n%s', data)
```
The [filter.py](./cuckoo/filter.py) parse the branch data and make a new clean log file.

```Python
with open(analysis_path % filt) as f:
    log = f.read()

if '+' not in log:
    shutil.rmtree('./' + filt)
else:
    liner = log.replace('\r', '').split('\n')
    branch = filter(lambda x: '+' in x, liner)
    data = '\n'.join(branch)

    with open(log_path % filt, 'w') as branch_log:
        branch_log.write(data + '\n')
```

## Data

Top 1000 Windows API called by malware samples.

Sample dataset consisted of 470 malware branch data and 40 normal software branch data. It's very unbalanced classification problem, so I make dataset seperately. Then train it with [BiasedDataset](./utils/dataset.py) which automatically rotate normal trainset to feed balanced dataset.

## Classifier

Classification problem between malware and normal software. Dataset is the preprocessed branch data.

```python
model = tf.keras.Sequential()
model.add(tf.keras.layers.Embedding(self.embedding_size, 500))
model.add(tf.keras.layers.LSTM(256))
model.add(tf.keras.layers.Dense(1))
```

First, embed the symbol index to 500D vector. Then pass it to the LSTM and Dense layer to make single probability. 

<img src="./rsrc/loss.png" width="40%">
<img src="./rsrc/accuracy.png", width="40%">

I was able to get a classifier with 88% validation accuracy.

## Result

Since the dataset is too small that those accuracy and loss value is untrustable, but the possibility is proved I think.

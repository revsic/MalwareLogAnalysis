import os
import time

import numpy as np
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self, embedding_size):
        super(Model, self).__init__()
        self.embedding_size = embedding_size

        self.model = tf.keras.Sequential()
        self.model.add(tf.keras.layers.Embedding(self.embedding_size, 500))
        self.model.add(tf.keras.layers.LSTM(256))
        self.model.add(tf.keras.layers.Dense(1))

    def call(self, input_layer, training=True):
        return self.model(input_layer)


class MalwareDetector:
    def __init__(self, seqlen, embedding_size, sess=None):
        self.seqlen = seqlen
        self.embedding_size = embedding_size
        self.model = Model(self.embedding_size)
        self.sess = tf.compat.v1.Session() if sess is None else sess

        self.inputs = tf.compat.v1.placeholder(tf.int32, [None, self.seqlen])
        self.output = tf.compat.v1.placeholder(tf.int32, [None])

        self.logits = self.model(self.inputs)
        self.pred = tf.cast(self.logits > 0, tf.int32)

        loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)
        self.loss = loss_object(self.output[..., None], self.logits)

        self.opt = tf.compat.v1.train.AdamOptimizer(1e-2).minimize(self.loss)

        correct = tf.equal(self.pred, self.output[..., None])
        self.metric = tf.reduce_mean(tf.cast(correct, tf.float32))

        self.sloss = tf.compat.v1.placeholder(tf.float32)
        self.smetric = tf.compat.v1.placeholder(tf.float32)
        self.summary = tf.compat.v1.summary.merge([
            tf.compat.v1.summary.scalar('loss', self.sloss),
            tf.compat.v1.summary.scalar('accuracy', self.smetric)
        ])

        self.checkpoint = tf.compat.v1.train.Saver()
        self.sess.run(tf.compat.v1.global_variables_initializer())
    
    def save(self, ckpt_dir, step=None):
        self.checkpoint.save(self.sess, ckpt_dir, global_step=step)
    
    def restore(self, ckpt_dir='./ckpt'):
        path = tf.train.latest_checkpoint(ckpt_dir)
        self.checkpoint.restore(self.sess, path)

    def inference(self, inputs):
        return self.sess.run(self.pred, feed_dict={self.inputs: inputs})

    def train(self,
              trainset,
              valset,
              epochs,
              ckpt_interval,
              ckpt_dir='./ckpt',
              summary_dir='./summary',
              name='default'):
        if not os.path.exists(ckpt_dir):
            os.makedirs(ckpt_dir)

        ckpt_dir = os.path.join(ckpt_dir, name)
        summary_dir = os.path.join(summary_dir, name)
        if not os.path.exists(summary_dir):
            os.makedirs(summary_dir)
        
        summary_val = tf.compat.v1.summary.FileWriter(os.path.join(summary_dir, 'val'), self.sess.graph)
        summary_train = tf.compat.v1.summary.FileWriter(os.path.join(summary_dir, 'train'), self.sess.graph)

        for epoch in range(epochs):
            start = time.time()

            tloss, tmetric, tpred = self.loop(trainset, self.train_step, 'train')
            self.write_summary(tloss, tmetric, epoch, summary_train)

            vloss, vmetric, vpred = self.loop(valset, self.validation_step, 'val')
            self.write_summary(vloss, vmetric, epoch, summary_val)

            if (epoch + 1) % ckpt_interval == 0:
                self.save(ckpt_dir, epoch)

            print('\r{} epoch, {} sec, train loss={:.5f}, train metric={:.5f}, val loss={:.5f}, val metric={:.5f}'.format(
                epoch + 1, time.time() - start, tloss, tmetric, vloss, vmetric))
            print('{} epoch, train pred=[{}]'.format(epoch + 1, tpred))
            print('{} epoch, valid pred=[{}]'.format(epoch + 1, vpred))

    def loop(self, dataset, step, name, print_pred=False):
        losses, metrics = [], []
        for idx, datum in enumerate(dataset):
            loss, metric, pred = step(*datum)
            print('\r{}: {}, loss={:.5f}, metric={:.5f}'.format(name, idx, loss, metric), end='')

            losses.append(loss)
            metrics.append(metric)

        pred = ', '.join(str(p) for p in pred.reshape(-1))
        return np.mean(losses), np.mean(metric), pred

    def train_step(self, inputs, outputs):
        _, loss, metric, pred = self.sess.run((self.opt, self.loss, self.metric, self.pred),
                                              feed_dict={self.inputs: inputs, self.output: outputs})
        return loss, metric, pred

    def validation_step(self, inputs, outputs):
        loss, metric, pred = self.sess.run((self.loss, self.metric, self.pred),
                                           feed_dict={self.inputs: inputs, self.output: outputs})
        return loss, metric, pred

    def write_summary(self, loss, metric, epoch, writer):
        res = self.sess.run(self.summary, feed_dict={self.sloss: loss, self.smetric: metric})
        writer.add_summary(res, global_step=epoch)
